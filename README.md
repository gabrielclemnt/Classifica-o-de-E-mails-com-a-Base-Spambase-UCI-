
# Classifica√ß√£o de E-mails com a Base Spambase (UCI)

Este projeto utiliza a base de dados Spambase do UCI Machine Learning Repository para construir e comparar modelos de classifica√ß√£o de e-mails em spam e n√£o spam. O projeto foi desenvolvido no Google Colab, com o uso da biblioteca Scikit-learn.

üìä Objetivo
Aplicar e comparar o desempenho de quatro algoritmos de classifica√ß√£o:

√Årvore de Decis√£o

Naive Bayes (Bayesiano Ing√™nuo)

Regress√£o Log√≠stica

K-Vizinhos mais pr√≥ximos (KNN) com dist√¢ncia Euclidiana

üß™ Metodologia
Divis√£o dos dados: Estratificada e aleat√≥ria, com 70% dos dados para treinamento + valida√ß√£o e 30% para teste.

Valida√ß√£o de hiperpar√¢metros:

Modelos com hiperpar√¢metros foram ajustados via valida√ß√£o cruzada apenas no conjunto de treino/valida√ß√£o.

O conjunto de teste foi utilizado somente para avalia√ß√£o final dos modelos.

M√©tricas de avalia√ß√£o:

Precis√£o (Precision)

Cobertura (Recall)

F1-Score

üìà Curvas de Aprendizado
Para cada classificador com sua melhor configura√ß√£o de hiperpar√¢metros, foram geradas curvas de aprendizado, variando a propor√ß√£o de dados de treinamento de 5% at√© 95% (com passo de 5%). As m√©tricas de avalia√ß√£o foram plotadas em fun√ß√£o do tamanho do conjunto de treinamento. Isso permite analisar o comportamento dos modelos conforme o volume de dados dispon√≠veis.

üîß Ferramentas Utilizadas
Google Colab

Scikit-learn

Matplotlib

Pandas

NumPy

üìÇ Organiza√ß√£o do Projeto
spambase_classification.ipynb ‚Äî Notebook principal com a implementa√ß√£o completa.

spambase.data ‚Äî Dados originais da base (dispon√≠vel via UCI ou reposit√≥rio local).

README.md ‚Äî Este arquivo.

üìå Resultados
Os modelos foram comparados com base em suas m√©tricas no conjunto de teste. Tamb√©m foi feita uma an√°lise das curvas de aprendizado para cada algoritmo. Os melhores resultados variaram de acordo com as m√©tricas, sendo o KNN e a Regress√£o Log√≠stica os modelos com desempenho mais consistente.

Este projeto mostrou a import√¢ncia da valida√ß√£o de hiperpar√¢metros e da an√°lise de curvas de aprendizado na constru√ß√£o de modelos robustos. Al√©m disso, refor√ßa a relev√¢ncia do particionamento correto dos dados para evitar overfitting ou vi√©s de avalia√ß√£o.

